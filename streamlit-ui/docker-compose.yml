version: '3.8'

services:
  jarvis-ui:
    build:
      context: ./jarvis-ui
      dockerfile: Dockerfile
    ports:
      - "8501:8501"
    volumes:
    # Consider adding volumes for the screenshots as well
      - ./jarvis-ui/auth/config.yaml:/app/auth/config.yaml
      - ./jarvis-ui/chunks:/app/chunks
      - ./jarvis-ui/chat_history:/app/chat_history
      - ./jarvis-ui/output:/app/output
      - ./jarvis-ui/documents:/app/documents
    depends_on:
      - nlm-ingestor # for chunking during uploading

  orchestrator:
    build:
      context: ./orchestrator
      dockerfile: Dockerfile
    expose:
      - "5010"
    depends_on:
      - ollama
      - neo4j

  neo4j:
    image: neo4j:5.20.0
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - $HOME/neo4j/data:/data
    
  nlm-ingestor:
    image: ghcr.io/nlmatics/nlm-ingestor:latest
    expose:
      - "5001"
  
  ollama:
    image: ollama/ollama:latest
    expose:
      - 11434 # for communication b/w containers within network
    environment:
      OLLAMA_NUM_PARALLEL: "4" # adjust if needed
    volumes:
      - ollama:/root/.ollama
      - ./ollama_entrypoint.sh:/ollama_entrypoint.sh
    container_name: ollama
    pull_policy: always
    tty: true
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['all']
              capabilities: [gpu]
    entrypoint: ["/usr/bin/bash", "/ollama_entrypoint.sh"]

volumes:
  ollama:
  jarvis-ui:
  neo4j: