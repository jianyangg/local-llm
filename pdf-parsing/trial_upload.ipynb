{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from string import Template\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "import glob\n",
    "from timeit import default_timer as timer\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep\n",
    "import os\n",
    "\n",
    "import streamlit as st\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from streamlit.logger import get_logger\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import Dict, List\n",
    "from langchain_community.llms import Ollama\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"ollama_base_url\": \"http://localhost:11434\",\n",
    "        \"llm_name\": \"llama3\",\n",
    "        \"neo4j_url\": \"neo4j://localhost:7687\",\n",
    "        \"neo4j_username\": \"neo4j\",\n",
    "        \"neo4j_password\": \"password\",\n",
    "        \"file_path\": \"data/markdown.md\",\t\t\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: As this json requires extracting entities from text, a bit of courage and creativity is required by the model.\n",
    "# Hence, we use a higher temperature to allow for more creative responses.\n",
    "llm = Ollama(model=\"llama3\", temperature=0.2, format=\"json\", base_url=\"http://localhost:11434\")\n",
    "llm_no_json = Ollama(model=\"llama3\", temperature=0.3, base_url=\"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j configuration & constraints\n",
    "url=config[\"neo4j_url\"] #database url\n",
    "username=config[\"neo4j_username\"] #neo4j username\n",
    "password=config[\"neo4j_password\"] #neo4j password\n",
    "gds = GraphDatabase.driver(url, auth=(username, password))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to specify the tenant id to achieve isolation in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc = config[\"file_path\"]\n",
    "with open(file_loc, 'r') as file:\n",
    "    text = file.read().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"entities\" : [\n",
      "  { \"type\": \"PERSON\", \"name\": \"JOSEPH R. BIDEN, Jr.\" },\n",
      "  { \"type\": \"ORGANIZATION\", \"name\": \"THEWHITEHOUSE\" },\n",
      "  { \"type\": \"DATE\", \"value\": \"March 7, 2024\" },\n",
      "  { \"type\": \"LOCATION\", \"name\": \"United States of America\" },\n",
      "  { \"type\": \"GOVERNMENT\", \"name\": \"House of Representatives\" },\n",
      "  { \"type\": \"PERSON\", \"name\": \"Mrs. Alli\" },\n",
      "  { \"type\": \"PERSON\", \"name\": \"Mrs. Cole\" },\n",
      "  { \"type\": \"PERSON\", \"name\": \"MRS. MURRAY\" },\n",
      "  { \"type\": \"ORGANIZATION\", \"name\": \"Environmental Protection Agency\" },\n",
      "  { \"type\": \"PERSON\", \"name\": \"Administrator of the Environmental Protection Agency\" },\n",
      "  { \"type\": \"ORGANIZATION\", \"name\": \"Fish and Wildlife Service\" },\n",
      "  { \"type\": \"PERSON\", \"name\": \"Deputy Assistant Director of the Migratory Bird Program\" },\n",
      "  { \"type\": \"ORGANIZATION\", \"name\": \"Department of Health and Human Services\" },\n",
      "  { \"type\": \"PERSON\", \"name\": \"Assistant Secretary for Legislation, Department of Health and Human Services\" },\n",
      "  { \"type\": \"ORGANIZATION\", \"name\": \"Centers for Medicare and Medicaid Services\" },\n",
      "  { \"type\": \"REGULATION\", \"name\": \"Firefighter Cancer Registry Act of 2018\" },\n",
      "  { \"type\": \"REGULATION\", \"name\": \"Airport Improvement Program\" },\n",
      "  { \"type\": \"REGULATION\", \"name\": \"Internal Revenue Code of 1986\" },\n",
      "  { \"type\": \"REGULATION\", \"name\": \"Medicare Prescription Payment Plan\" },\n",
      "  { \"type\": \"REGULATION\", \"name\": \"Health Resources Priorities and Allocations System\" }\n",
      "] }\n"
     ]
    }
   ],
   "source": [
    "prompt = \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>Extract ALL entities from this text. DO not miss out anything. <|start_header_id|>user<|end_header_id|> Text: \" + text + \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
    "entities = llm.invoke(prompt)\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We might need a human in the loop here to verify entities and relationship, especially the ones with a missing link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \n",
      "\"has_skill\": [\n",
      "    {\"subject\": \"Sarah Johnson\", \"object\": \"Machine Learning\"},\n",
      "    {\"subject\": \"Sarah Johnson\", \"object\": \"Data Analytics\"},\n",
      "    {\"subject\": \"Sarah Johnson\", \"object\": \"Azure\"},\n",
      "    {\"subject\": \"Sarah Johnson\", \"object\": \"Python\"},\n",
      "    {\"subject\": \"David Patel\", \"object\": \"AWS\"},\n",
      "    {\"subject\": \"David Patel\", \"object\": \"Cloud Computing\"},\n",
      "    {\"subject\": \"David Patel\", \"object\": \"DevOps\"},\n",
      "    {\"subject\": \"David Patel\", \"object\": \"Data Warehousing\"},\n",
      "    {\"subject\": \"Amanda Rodriguez\", \"object\": \"Data Security\"},\n",
      "    {\"subject\": \"Amanda Rodriguez\", \"object\": \"Compliance\"},\n",
      "    {\"subject\": \"Amanda Rodriguez\", \"object\": \"Healthcare Regulations\"},\n",
      "    {\"subject\": \"Amanda Rodriguez\", \"object\": \"Azure\"}\n",
      "],\n",
      "\"worked_on_project\": [\n",
      "    {\"subject\": \"Sarah Johnson\", \"object\": \"BetaHealth Secure Healthcare Data Analytics Platform on Azure\"}\n",
      "]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>Extract all relationships from the text and entities given. DO NOT GENERATE RELATIONSHIPS BETWEEN ENTITIES THAT ARE NOT GIVEN BELOW. Ensure that the entities for each relationship exist and are referenced from the entities list given. <|start_header_id|>user<|end_header_id|> Text: \" + text + \"Entities:\" + entities + \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
    "rs = llm.invoke(prompt)\n",
    "print(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"label\": \"Person\",\n",
      "      \"id\": \"sarah_johnson\",\n",
      "      \"name\": \"Sarah Johnson\",\n",
      "      \"summary\": \"\",\n",
      "      \"additional_properties\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"Person\",\n",
      "      \"id\": \"david_patel\",\n",
      "      \"name\": \"David Patel\",\n",
      "      \"summary\": \"\",\n",
      "      \"additional_properties\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"Person\",\n",
      "      \"id\": \"amanda_rodriguez\",\n",
      "      \"name\": \"Amanda Rodriguez\",\n",
      "      \"summary\": \"\",\n",
      "      \"additional_properties\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"Skill\",\n",
      "      \"id\": \"machine_learning\",\n",
      "      \"name\": \"Machine Learning\",\n",
      "      \"summary\": \"\",\n",
      "      \"additional_properties\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"Skill\",\n",
      "      \"id\": \"data_analytics\",\n",
      "      \"name\": \"Data Analytics\",\n",
      "      \"summary\": \"\",\n",
      "      \"additional_properties\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"Skill\",\n",
      "      \"id\": \"azure\",\n",
      "      \"name\": \"Azure\",\n",
      "      \"summary\": \"\",\n",
      "      \"additional_properties\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"Skill\",\n",
      "      \"id\": \"python\",\n",
      "      \"name\": \"Python\",\n",
      "      \"summary\": \"\",\n",
      "      \"additional_properties\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"Skill\",\n",
      "      \"id\": \"aws\",\n",
      "      \"name\": \"AWS\",\n",
      "      \"summary\": \"\",\n",
      "      \"additional_properties\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"Skill\",\n",
      "      \"id\": \"cloud_computing\",\n",
      "      \"name\": \"Cloud Computing\",\n",
      "      \"summary\": \"\",\n",
      "      \"additional_properties\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"Skill\",\n",
      "      \"id\": \"devops\",\n",
      "      \"name\": \"DevOps\",\n",
      "      \"summary\": \"\",\n",
      "      \"additional_properties\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"Skill\",\n",
      "      \"id\": \"data_warehousing\",\n",
      "      \"name\": \"Data Warehousing\",\n",
      "      \"summary\": \"\",\n",
      "      \"additional_properties\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"Skill\",\n",
      "      \"id\": \"data_security\",\n",
      "      \"name\": \"Data Security\",\n",
      "      \"summary\": \"\",\n",
      "      \"additional_properties\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"Skill\",\n",
      "      \"id\": \"compliance\",\n",
      "      \"name\": \"Compliance\",\n",
      "      \"summary\": \"\",\n",
      "      \"additional_properties\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"Skill\",\n",
      "      \"id\": \"healthcare_regulations\",\n",
      "      \"name\": \"Healthcare Regulations\",\n",
      "      \"summary\": \"\",\n",
      "      \"additional_properties\": \"\"\n",
      "    }\n",
      "  ],\n",
      "  \"relationships\": [\n",
      "    \"sarah_johnson|HAS_SKILL|machine_learning\",\n",
      "    \"sarah_johnson|HAS_SKILL|data_analytics\",\n",
      "    \"sarah_johnson|HAS_SKILL|azure\",\n",
      "    \"sarah_johnson|HAS_SKILL|python\",\n",
      "    \"david_patel|HAS_SKILL|aws\",\n",
      "    \"david_patel|HAS_SKILL|cloud_computing\",\n",
      "    \"david_patel|HAS_SKILL|devops\",\n",
      "    \"david_patel|HAS_SKILL|data_warehousing\",\n",
      "    \"amanda_rodriguez|HAS_SKILL|data_security\",\n",
      "    \"amanda_rodriguez|HAS_SKILL|compliance\",\n",
      "    \"amanda_rodriguez|HAS_SKILL|healthcare_regulations\",\n",
      "    \"amanda_rodriguez|HAS_SKILL|azure\",\n",
      "    \"sarah_johnson|WORKED_ON_PROJECT|BetaHealth Secure Healthcare Data Analytics Platform on Azure\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Prompt for generating Cypher queries from text\n",
    "cypher_generation_template_0 = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "Based on the entities and relationships given, format them into the following output. You can include additional context from the text as well.\n",
    "\n",
    "0. ALWAYS FINISH THE OUTPUT. Never send partial responses.\n",
    "\n",
    "1. The output should look like:\n",
    "{\n",
    "    \"entities\": [{\"label\":\"EntityType\",\"id\":string,\"name\":string,\"summary\":string, \"additional_properties\": string}],\n",
    "    \"relationships\": [\"entityid1|RELATIONSHIP_VERB|entityid2\"]\n",
    "}\n",
    "\n",
    "2. Some other formatting:\n",
    "    - RELATIONSHIP_VERB should be in uppercase and not have spaces.\n",
    "    - ids should not have spaces.\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Text to Process:\n",
    "$text\n",
    "\n",
    "Entities:\n",
    "$entities\n",
    "\n",
    "Relationships:\n",
    "$relationships\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt = Template(cypher_generation_template_0).substitute(text=text, entities=entities, relationships=rs)\n",
    "result = llm.invoke(prompt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_obj = json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_objS = []\n",
    "json_objS.append(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entities': [{'label': 'Person', 'id': 'sarah_johnson', 'name': 'Sarah Johnson', 'summary': '', 'additional_properties': ''}, {'label': 'Person', 'id': 'david_patel', 'name': 'David Patel', 'summary': '', 'additional_properties': ''}, {'label': 'Person', 'id': 'amanda_rodriguez', 'name': 'Amanda Rodriguez', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'machine_learning', 'name': 'Machine Learning', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'data_analytics', 'name': 'Data Analytics', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'azure', 'name': 'Azure', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'python', 'name': 'Python', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'aws', 'name': 'AWS', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'cloud_computing', 'name': 'Cloud Computing', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'devops', 'name': 'DevOps', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'data_warehousing', 'name': 'Data Warehousing', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'data_security', 'name': 'Data Security', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'compliance', 'name': 'Compliance', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'healthcare_regulations', 'name': 'Healthcare Regulations', 'summary': '', 'additional_properties': ''}], 'relationships': ['sarah_johnson|HAS_SKILL|machine_learning', 'sarah_johnson|HAS_SKILL|data_analytics', 'sarah_johnson|HAS_SKILL|azure', 'sarah_johnson|HAS_SKILL|python', 'david_patel|HAS_SKILL|aws', 'david_patel|HAS_SKILL|cloud_computing', 'david_patel|HAS_SKILL|devops', 'david_patel|HAS_SKILL|data_warehousing', 'amanda_rodriguez|HAS_SKILL|data_security', 'amanda_rodriguez|HAS_SKILL|compliance', 'amanda_rodriguez|HAS_SKILL|healthcare_regulations', 'amanda_rodriguez|HAS_SKILL|azure', 'sarah_johnson|WORKED_ON_PROJECT|BetaHealth Secure Healthcare Data Analytics Platform on Azure']}\n",
      "0\n",
      "[{'label': 'Person', 'id': 'sarah_johnson', 'name': 'Sarah Johnson', 'summary': '', 'additional_properties': ''}, {'label': 'Person', 'id': 'david_patel', 'name': 'David Patel', 'summary': '', 'additional_properties': ''}, {'label': 'Person', 'id': 'amanda_rodriguez', 'name': 'Amanda Rodriguez', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'machine_learning', 'name': 'Machine Learning', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'data_analytics', 'name': 'Data Analytics', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'azure', 'name': 'Azure', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'python', 'name': 'Python', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'aws', 'name': 'AWS', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'cloud_computing', 'name': 'Cloud Computing', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'devops', 'name': 'DevOps', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'data_warehousing', 'name': 'Data Warehousing', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'data_security', 'name': 'Data Security', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'compliance', 'name': 'Compliance', 'summary': '', 'additional_properties': ''}, {'label': 'Skill', 'id': 'healthcare_regulations', 'name': 'Healthcare Regulations', 'summary': '', 'additional_properties': ''}]\n",
      "['sarah_johnson|HAS_SKILL|machine_learning', 'sarah_johnson|HAS_SKILL|data_analytics', 'sarah_johnson|HAS_SKILL|azure', 'sarah_johnson|HAS_SKILL|python', 'david_patel|HAS_SKILL|aws', 'david_patel|HAS_SKILL|cloud_computing', 'david_patel|HAS_SKILL|devops', 'david_patel|HAS_SKILL|data_warehousing', 'amanda_rodriguez|HAS_SKILL|data_security', 'amanda_rodriguez|HAS_SKILL|compliance', 'amanda_rodriguez|HAS_SKILL|healthcare_regulations', 'amanda_rodriguez|HAS_SKILL|azure', 'sarah_johnson|WORKED_ON_PROJECT|BetaHealth Secure Healthcare Data Analytics Platform on Azure']\n"
     ]
    }
   ],
   "source": [
    "for i, obj in enumerate(json_objS):\n",
    "    print(obj)\n",
    "    print(i)\n",
    "    print(obj['entities'])\n",
    "    print(obj['relationships'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenant_id = \"tenant1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the following block's TODO carefully. It's key in achieving pseudo-isolation in our Neo4j database (since we don't have the enterprise edition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating cypher for file 1 of 2\n",
      "\n",
      "0 <class 'dict'>\n",
      "0 <class 'dict'>\n",
      "0 <class 'dict'>\n",
      "0 <class 'dict'>\n",
      "0 <class 'dict'>\n",
      "0 <class 'dict'>\n",
      "0 <class 'dict'>\n",
      "0 <class 'dict'>\n",
      "0 <class 'dict'>\n",
      "0 <class 'dict'>\n",
      "0 <class 'dict'>\n",
      "0 <class 'dict'>\n",
      "0 <class 'dict'>\n",
      "0 <class 'dict'>\n",
      "src_id sarahjohnson\n",
      "tgt_id machinelearning\n",
      "{'amandarodriguez': 'Person',\n",
      " 'aws': 'Skill',\n",
      " 'azure': 'Skill',\n",
      " 'cloudcomputing': 'Skill',\n",
      " 'compliance': 'Skill',\n",
      " 'dataanalytics': 'Skill',\n",
      " 'datasecurity': 'Skill',\n",
      " 'datawarehousing': 'Skill',\n",
      " 'davidpatel': 'Person',\n",
      " 'devops': 'Skill',\n",
      " 'healthcareregulations': 'Skill',\n",
      " 'machinelearning': 'Skill',\n",
      " 'python': 'Skill',\n",
      " 'sarahjohnson': 'Person'}\n",
      "rs_type HAS_SKILL\n",
      "src_id sarahjohnson\n",
      "tgt_id dataanalytics\n",
      "{'amandarodriguez': 'Person',\n",
      " 'aws': 'Skill',\n",
      " 'azure': 'Skill',\n",
      " 'cloudcomputing': 'Skill',\n",
      " 'compliance': 'Skill',\n",
      " 'dataanalytics': 'Skill',\n",
      " 'datasecurity': 'Skill',\n",
      " 'datawarehousing': 'Skill',\n",
      " 'davidpatel': 'Person',\n",
      " 'devops': 'Skill',\n",
      " 'healthcareregulations': 'Skill',\n",
      " 'machinelearning': 'Skill',\n",
      " 'python': 'Skill',\n",
      " 'sarahjohnson': 'Person'}\n",
      "rs_type HAS_SKILL\n",
      "src_id sarahjohnson\n",
      "tgt_id azure\n",
      "{'amandarodriguez': 'Person',\n",
      " 'aws': 'Skill',\n",
      " 'azure': 'Skill',\n",
      " 'cloudcomputing': 'Skill',\n",
      " 'compliance': 'Skill',\n",
      " 'dataanalytics': 'Skill',\n",
      " 'datasecurity': 'Skill',\n",
      " 'datawarehousing': 'Skill',\n",
      " 'davidpatel': 'Person',\n",
      " 'devops': 'Skill',\n",
      " 'healthcareregulations': 'Skill',\n",
      " 'machinelearning': 'Skill',\n",
      " 'python': 'Skill',\n",
      " 'sarahjohnson': 'Person'}\n",
      "rs_type HAS_SKILL\n",
      "src_id sarahjohnson\n",
      "tgt_id python\n",
      "{'amandarodriguez': 'Person',\n",
      " 'aws': 'Skill',\n",
      " 'azure': 'Skill',\n",
      " 'cloudcomputing': 'Skill',\n",
      " 'compliance': 'Skill',\n",
      " 'dataanalytics': 'Skill',\n",
      " 'datasecurity': 'Skill',\n",
      " 'datawarehousing': 'Skill',\n",
      " 'davidpatel': 'Person',\n",
      " 'devops': 'Skill',\n",
      " 'healthcareregulations': 'Skill',\n",
      " 'machinelearning': 'Skill',\n",
      " 'python': 'Skill',\n",
      " 'sarahjohnson': 'Person'}\n",
      "rs_type HAS_SKILL\n",
      "src_id davidpatel\n",
      "tgt_id aws\n",
      "{'amandarodriguez': 'Person',\n",
      " 'aws': 'Skill',\n",
      " 'azure': 'Skill',\n",
      " 'cloudcomputing': 'Skill',\n",
      " 'compliance': 'Skill',\n",
      " 'dataanalytics': 'Skill',\n",
      " 'datasecurity': 'Skill',\n",
      " 'datawarehousing': 'Skill',\n",
      " 'davidpatel': 'Person',\n",
      " 'devops': 'Skill',\n",
      " 'healthcareregulations': 'Skill',\n",
      " 'machinelearning': 'Skill',\n",
      " 'python': 'Skill',\n",
      " 'sarahjohnson': 'Person'}\n",
      "rs_type HAS_SKILL\n",
      "src_id davidpatel\n",
      "tgt_id cloudcomputing\n",
      "{'amandarodriguez': 'Person',\n",
      " 'aws': 'Skill',\n",
      " 'azure': 'Skill',\n",
      " 'cloudcomputing': 'Skill',\n",
      " 'compliance': 'Skill',\n",
      " 'dataanalytics': 'Skill',\n",
      " 'datasecurity': 'Skill',\n",
      " 'datawarehousing': 'Skill',\n",
      " 'davidpatel': 'Person',\n",
      " 'devops': 'Skill',\n",
      " 'healthcareregulations': 'Skill',\n",
      " 'machinelearning': 'Skill',\n",
      " 'python': 'Skill',\n",
      " 'sarahjohnson': 'Person'}\n",
      "rs_type HAS_SKILL\n",
      "src_id davidpatel\n",
      "tgt_id devops\n",
      "{'amandarodriguez': 'Person',\n",
      " 'aws': 'Skill',\n",
      " 'azure': 'Skill',\n",
      " 'cloudcomputing': 'Skill',\n",
      " 'compliance': 'Skill',\n",
      " 'dataanalytics': 'Skill',\n",
      " 'datasecurity': 'Skill',\n",
      " 'datawarehousing': 'Skill',\n",
      " 'davidpatel': 'Person',\n",
      " 'devops': 'Skill',\n",
      " 'healthcareregulations': 'Skill',\n",
      " 'machinelearning': 'Skill',\n",
      " 'python': 'Skill',\n",
      " 'sarahjohnson': 'Person'}\n",
      "rs_type HAS_SKILL\n",
      "src_id davidpatel\n",
      "tgt_id datawarehousing\n",
      "{'amandarodriguez': 'Person',\n",
      " 'aws': 'Skill',\n",
      " 'azure': 'Skill',\n",
      " 'cloudcomputing': 'Skill',\n",
      " 'compliance': 'Skill',\n",
      " 'dataanalytics': 'Skill',\n",
      " 'datasecurity': 'Skill',\n",
      " 'datawarehousing': 'Skill',\n",
      " 'davidpatel': 'Person',\n",
      " 'devops': 'Skill',\n",
      " 'healthcareregulations': 'Skill',\n",
      " 'machinelearning': 'Skill',\n",
      " 'python': 'Skill',\n",
      " 'sarahjohnson': 'Person'}\n",
      "rs_type HAS_SKILL\n",
      "src_id amandarodriguez\n",
      "tgt_id datasecurity\n",
      "{'amandarodriguez': 'Person',\n",
      " 'aws': 'Skill',\n",
      " 'azure': 'Skill',\n",
      " 'cloudcomputing': 'Skill',\n",
      " 'compliance': 'Skill',\n",
      " 'dataanalytics': 'Skill',\n",
      " 'datasecurity': 'Skill',\n",
      " 'datawarehousing': 'Skill',\n",
      " 'davidpatel': 'Person',\n",
      " 'devops': 'Skill',\n",
      " 'healthcareregulations': 'Skill',\n",
      " 'machinelearning': 'Skill',\n",
      " 'python': 'Skill',\n",
      " 'sarahjohnson': 'Person'}\n",
      "rs_type HAS_SKILL\n",
      "src_id amandarodriguez\n",
      "tgt_id compliance\n",
      "{'amandarodriguez': 'Person',\n",
      " 'aws': 'Skill',\n",
      " 'azure': 'Skill',\n",
      " 'cloudcomputing': 'Skill',\n",
      " 'compliance': 'Skill',\n",
      " 'dataanalytics': 'Skill',\n",
      " 'datasecurity': 'Skill',\n",
      " 'datawarehousing': 'Skill',\n",
      " 'davidpatel': 'Person',\n",
      " 'devops': 'Skill',\n",
      " 'healthcareregulations': 'Skill',\n",
      " 'machinelearning': 'Skill',\n",
      " 'python': 'Skill',\n",
      " 'sarahjohnson': 'Person'}\n",
      "rs_type HAS_SKILL\n",
      "src_id amandarodriguez\n",
      "tgt_id healthcareregulations\n",
      "{'amandarodriguez': 'Person',\n",
      " 'aws': 'Skill',\n",
      " 'azure': 'Skill',\n",
      " 'cloudcomputing': 'Skill',\n",
      " 'compliance': 'Skill',\n",
      " 'dataanalytics': 'Skill',\n",
      " 'datasecurity': 'Skill',\n",
      " 'datawarehousing': 'Skill',\n",
      " 'davidpatel': 'Person',\n",
      " 'devops': 'Skill',\n",
      " 'healthcareregulations': 'Skill',\n",
      " 'machinelearning': 'Skill',\n",
      " 'python': 'Skill',\n",
      " 'sarahjohnson': 'Person'}\n",
      "rs_type HAS_SKILL\n",
      "src_id amandarodriguez\n",
      "tgt_id azure\n",
      "{'amandarodriguez': 'Person',\n",
      " 'aws': 'Skill',\n",
      " 'azure': 'Skill',\n",
      " 'cloudcomputing': 'Skill',\n",
      " 'compliance': 'Skill',\n",
      " 'dataanalytics': 'Skill',\n",
      " 'datasecurity': 'Skill',\n",
      " 'datawarehousing': 'Skill',\n",
      " 'davidpatel': 'Person',\n",
      " 'devops': 'Skill',\n",
      " 'healthcareregulations': 'Skill',\n",
      " 'machinelearning': 'Skill',\n",
      " 'python': 'Skill',\n",
      " 'sarahjohnson': 'Person'}\n",
      "rs_type HAS_SKILL\n",
      "src_id sarahjohnson\n",
      "tgt_id BetaHealth Secure Healthcare Data Analytics Platform on Azure\n",
      "{'amandarodriguez': 'Person',\n",
      " 'aws': 'Skill',\n",
      " 'azure': 'Skill',\n",
      " 'cloudcomputing': 'Skill',\n",
      " 'compliance': 'Skill',\n",
      " 'dataanalytics': 'Skill',\n",
      " 'datasecurity': 'Skill',\n",
      " 'datawarehousing': 'Skill',\n",
      " 'davidpatel': 'Person',\n",
      " 'devops': 'Skill',\n",
      " 'healthcareregulations': 'Skill',\n",
      " 'machinelearning': 'Skill',\n",
      " 'python': 'Skill',\n",
      " 'sarahjohnson': 'Person'}\n",
      "rs_type WORKED_ON_PROJECT\n",
      "KeyError: BetaHealth Secure Healthcare Data Analytics Platform on Azure not found in e_label_map\n"
     ]
    }
   ],
   "source": [
    "e_statements = []\n",
    "r_statements = []\n",
    "e_label_map = {}\n",
    "\n",
    "# loop through our json object\n",
    "for i, obj in enumerate(json_objS):\n",
    "    # for each dictionary item, do this...\n",
    "    # entities is a dictionary of dictionaries\n",
    "    print(f\"Generating cypher for file {i+1} of {len(json_obj)}\")\n",
    "    print()\n",
    "    for entity in obj[\"entities\"]:\n",
    "        print(i, type(entity))\n",
    "        label = entity[\"label\"]\n",
    "        id = entity[\"id\"]\n",
    "        id = id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "        # classifying all the information of a node into just labels, id, and properties (whcih stores the rest of the information)\n",
    "        properties = {k: v for k, v in entity.items() if k not in [\"label\", \"id\"]}\n",
    "\n",
    "        # TODO: Use the :tenant_id label to fetch only the nodes that belong to the tenant\n",
    "        cypher = f'MERGE (n:{tenant_id}:{label} {{id: \"{id}\"}})'\n",
    "        if properties:\n",
    "            props_str = \", \".join(\n",
    "                [f'n.{key} = \"{val}\"' for key, val in properties.items()]\n",
    "            )\n",
    "            cypher += f\" ON CREATE SET {props_str}\"\n",
    "        e_statements.append(cypher)\n",
    "        e_label_map[id] = label\n",
    "\n",
    "    for rs in obj[\"relationships\"]:\n",
    "        src_id, rs_type, tgt_id = rs.split(\"|\")\n",
    "        src_id = src_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "        print(\"src_id\", src_id) \n",
    "        tgt_id = tgt_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "        print(\"tgt_id\", tgt_id)\n",
    "        pprint(e_label_map)\n",
    "        print(\"rs_type\", rs_type)\n",
    "\n",
    "        src_label = e_label_map[src_id]\n",
    "        if tgt_id == \"\":\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                tgt_label = e_label_map[tgt_id]\n",
    "            except KeyError:\n",
    "                # Write to log\n",
    "                print(f\"KeyError: {tgt_id} not found in e_label_map\")\n",
    "                # Add the entity to the e_statements list\n",
    "                \n",
    "\n",
    "        cypher = f'MERGE (a:{tenant_id}:{src_label} {{id: \"{src_id}\"}}) MERGE (b:{tgt_label} {{id: \"{tgt_id}\"}}) MERGE (a)-[:{rs_type}]->(b)'\n",
    "        r_statements.append(cypher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MERGE (n:tenant1:Person {id: \"sarahjohnson\"}) ON CREATE SET n.name = \"Sarah Johnson\", n.summary = \"\", n.additional_properties = \"\"',\n",
       " 'MERGE (n:tenant1:Person {id: \"davidpatel\"}) ON CREATE SET n.name = \"David Patel\", n.summary = \"\", n.additional_properties = \"\"',\n",
       " 'MERGE (n:tenant1:Person {id: \"amandarodriguez\"}) ON CREATE SET n.name = \"Amanda Rodriguez\", n.summary = \"\", n.additional_properties = \"\"',\n",
       " 'MERGE (n:tenant1:Skill {id: \"machinelearning\"}) ON CREATE SET n.name = \"Machine Learning\", n.summary = \"\", n.additional_properties = \"\"',\n",
       " 'MERGE (n:tenant1:Skill {id: \"dataanalytics\"}) ON CREATE SET n.name = \"Data Analytics\", n.summary = \"\", n.additional_properties = \"\"',\n",
       " 'MERGE (n:tenant1:Skill {id: \"azure\"}) ON CREATE SET n.name = \"Azure\", n.summary = \"\", n.additional_properties = \"\"',\n",
       " 'MERGE (n:tenant1:Skill {id: \"python\"}) ON CREATE SET n.name = \"Python\", n.summary = \"\", n.additional_properties = \"\"',\n",
       " 'MERGE (n:tenant1:Skill {id: \"aws\"}) ON CREATE SET n.name = \"AWS\", n.summary = \"\", n.additional_properties = \"\"',\n",
       " 'MERGE (n:tenant1:Skill {id: \"cloudcomputing\"}) ON CREATE SET n.name = \"Cloud Computing\", n.summary = \"\", n.additional_properties = \"\"',\n",
       " 'MERGE (n:tenant1:Skill {id: \"devops\"}) ON CREATE SET n.name = \"DevOps\", n.summary = \"\", n.additional_properties = \"\"',\n",
       " 'MERGE (n:tenant1:Skill {id: \"datawarehousing\"}) ON CREATE SET n.name = \"Data Warehousing\", n.summary = \"\", n.additional_properties = \"\"',\n",
       " 'MERGE (n:tenant1:Skill {id: \"datasecurity\"}) ON CREATE SET n.name = \"Data Security\", n.summary = \"\", n.additional_properties = \"\"',\n",
       " 'MERGE (n:tenant1:Skill {id: \"compliance\"}) ON CREATE SET n.name = \"Compliance\", n.summary = \"\", n.additional_properties = \"\"',\n",
       " 'MERGE (n:tenant1:Skill {id: \"healthcareregulations\"}) ON CREATE SET n.name = \"Healthcare Regulations\", n.summary = \"\", n.additional_properties = \"\"']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MERGE (a:tenant1:Person {id: \"sarahjohnson\"}) MERGE (b:Skill {id: \"machinelearning\"}) MERGE (a)-[:HAS_SKILL]->(b)',\n",
       " 'MERGE (a:tenant1:Person {id: \"sarahjohnson\"}) MERGE (b:Skill {id: \"dataanalytics\"}) MERGE (a)-[:HAS_SKILL]->(b)',\n",
       " 'MERGE (a:tenant1:Person {id: \"sarahjohnson\"}) MERGE (b:Skill {id: \"azure\"}) MERGE (a)-[:HAS_SKILL]->(b)',\n",
       " 'MERGE (a:tenant1:Person {id: \"sarahjohnson\"}) MERGE (b:Skill {id: \"python\"}) MERGE (a)-[:HAS_SKILL]->(b)',\n",
       " 'MERGE (a:tenant1:Person {id: \"davidpatel\"}) MERGE (b:Skill {id: \"aws\"}) MERGE (a)-[:HAS_SKILL]->(b)',\n",
       " 'MERGE (a:tenant1:Person {id: \"davidpatel\"}) MERGE (b:Skill {id: \"cloudcomputing\"}) MERGE (a)-[:HAS_SKILL]->(b)',\n",
       " 'MERGE (a:tenant1:Person {id: \"davidpatel\"}) MERGE (b:Skill {id: \"devops\"}) MERGE (a)-[:HAS_SKILL]->(b)',\n",
       " 'MERGE (a:tenant1:Person {id: \"davidpatel\"}) MERGE (b:Skill {id: \"datawarehousing\"}) MERGE (a)-[:HAS_SKILL]->(b)',\n",
       " 'MERGE (a:tenant1:Person {id: \"amandarodriguez\"}) MERGE (b:Skill {id: \"datasecurity\"}) MERGE (a)-[:HAS_SKILL]->(b)',\n",
       " 'MERGE (a:tenant1:Person {id: \"amandarodriguez\"}) MERGE (b:Skill {id: \"compliance\"}) MERGE (a)-[:HAS_SKILL]->(b)',\n",
       " 'MERGE (a:tenant1:Person {id: \"amandarodriguez\"}) MERGE (b:Skill {id: \"healthcareregulations\"}) MERGE (a)-[:HAS_SKILL]->(b)',\n",
       " 'MERGE (a:tenant1:Person {id: \"amandarodriguez\"}) MERGE (b:Skill {id: \"azure\"}) MERGE (a)-[:HAS_SKILL]->(b)',\n",
       " 'MERGE (a:tenant1:Person {id: \"sarahjohnson\"}) MERGE (b:Skill {id: \"BetaHealth Secure Healthcare Data Analytics Platform on Azure\"}) MERGE (a)-[:WORKED_ON_PROJECT]->(b)']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cyphers.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(e_statements + r_statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing cypher statement 1 of 27\n",
      "Executing cypher statement 2 of 27\n",
      "Executing cypher statement 3 of 27\n",
      "Executing cypher statement 4 of 27\n",
      "Executing cypher statement 5 of 27\n",
      "Executing cypher statement 6 of 27\n",
      "Executing cypher statement 7 of 27\n",
      "Executing cypher statement 8 of 27\n",
      "Executing cypher statement 9 of 27\n",
      "Executing cypher statement 10 of 27\n",
      "Executing cypher statement 11 of 27\n",
      "Executing cypher statement 12 of 27\n",
      "Executing cypher statement 13 of 27\n",
      "Executing cypher statement 14 of 27\n",
      "Executing cypher statement 15 of 27\n",
      "Executing cypher statement 16 of 27\n",
      "Executing cypher statement 17 of 27\n",
      "Executing cypher statement 18 of 27\n",
      "Executing cypher statement 19 of 27\n",
      "Executing cypher statement 20 of 27\n",
      "Executing cypher statement 21 of 27\n",
      "Executing cypher statement 22 of 27\n",
      "Executing cypher statement 23 of 27\n",
      "Executing cypher statement 24 of 27\n",
      "Executing cypher statement 25 of 27\n",
      "Executing cypher statement 26 of 27\n",
      "Executing cypher statement 27 of 27\n"
     ]
    }
   ],
   "source": [
    "# Generate and execute cypher statements\n",
    "cypher_statements = e_statements + r_statements\n",
    "for i, stmt in enumerate(cypher_statements):\n",
    "    print(f\"Executing cypher statement {i+1} of {len(cypher_statements)}\")\n",
    "    try:\n",
    "        gds.execute_query(stmt)\n",
    "    except Exception as e:\n",
    "        with open(\"failed_statements.txt\", \"w\") as f:\n",
    "            f.write(f\"{stmt} - Exception: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
